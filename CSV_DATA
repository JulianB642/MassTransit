# -*- coding: utf-8 -*-
"""
Created on Thu Jun 25 10:51:18 2020

@author: Wenqing Zhong
"""

from bs4 import BeautifulSoup
import requests
from urllib.parse import urlparse, urljoin
from itertools import islice
import pandas as pd
import os



url = "http://web.mta.info/developers/turnstile.html"

def is_valid(url):
    parsed = urlparse(url)
    return bool(parsed.netloc) and bool(parsed.scheme)

def get_all_urls(url, limit):
    
    if(is_valid(url)==False):
        print("ERROR WITH URL INPUT")
       
    base=url
    soup = BeautifulSoup(requests.get(url).content, "html.parser")    
    urls=[]
    
    for link in islice(soup.find_all('a'),limit):       
        href = link.attrs.get("href")   
        if(str(href).startswith("data")== True):   
            full=urljoin(base, href)
            urls.append(full)           
    return urls


def get_data(url,i):
    r = requests.get(url)
    with open('data%s.txt'%i, 'w') as file:
        try:
            file.write(r.text)
        except:
            return False
        
    df = pd.read_csv("data%s.txt"%i,delimiter=',')
    df.to_csv('data%s.csv'%i)
    os.remove("data%s.txt"%i)
    return

       
def get_csv(url,limit):
    links=get_all_urls(url, limit)
    for i in range(len(links)):
        get_data(links[i],i)
    return

get_csv(url,50)    


